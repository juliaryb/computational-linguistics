{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4631730c",
   "metadata": {},
   "source": [
    "# Importing the dataset and data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d40a76",
   "metadata": {},
   "source": [
    "The AG News dataset is used for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a37a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770770dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"ag_news\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffdb602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 120000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 7600\n",
      "})\n",
      "\n",
      "Display a few samples:\n",
      "\n",
      " {'text': \"Flash dims AMD's revenue outlook The chipmaker's warning raises concerns about the flash memory business, one financial analyst says in a report.\", 'label': 3}\n",
      "\n",
      " {'text': \"They're quick to impress ATHENS -- Another night, another strong showing for America's sprinters. Allyson Felix , at 18 years old the youngest of the young lions, cruised to victory in her 200-meter heat, and then easily won her semifinal heat (22.36) to advance to the finals.\", 'label': 1}\n",
      "\n",
      " {'text': 'Viacom Starts Blockbuster Exchange Offer Viacom Inc. (VIAb.N: Quote, Profile, Research) has begun a share exchange offer to split off its Blockbuster Inc. (BBI.N: Quote, Profile, Research) unit and put the video rental chain ', 'label': 2}\n",
      "\n",
      " {'text': \"Microsoft Delays SP2 Delivery--Again Software giant allows users more time to prepare for XP's security fix.\", 'label': 3}\n",
      "\n",
      " {'text': \"Mount St. Helens Calms Down, Scientists Lower Alert (Reuters) Reuters - Government scientists said that\\\\volcanic activity on Washington state's Mount St. Helens had\\\\started to taper off and downgraded their safety warning on\\\\Wednesday, following nearly two weeks of seismic activity and\\\\steam eruptions.\", 'label': 3}\n"
     ]
    }
   ],
   "source": [
    "train_full = ds[\"train\"]\n",
    "test_full  = ds[\"test\"]\n",
    "\n",
    "print(train_full)\n",
    "print(test_full)\n",
    "\n",
    "print(\"\\nDisplay a few samples:\")\n",
    "for i in range(5):\n",
    "    print(\"\\n\", train_full[np.random.randint(train_full.num_rows)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b37543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
      "\n",
      "Train label counts:\n",
      "  0 - World: 30000\n",
      "  1 - Sports: 30000\n",
      "  2 - Business: 30000\n",
      "  3 - Sci/Tech: 30000\n",
      "\n",
      "Test label counts:\n",
      "  0 - World: 1900\n",
      "  1 - Sports: 1900\n",
      "  2 - Business: 1900\n",
      "  3 - Sci/Tech: 1900\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_names = train_full.features[\"label\"].names\n",
    "print(\"Label names:\", label_names)\n",
    "\n",
    "train_label_counts = Counter(train_full[\"label\"])\n",
    "test_label_counts  = Counter(test_full[\"label\"])\n",
    "\n",
    "print(\"\\nTrain label counts:\")\n",
    "for idx, name in enumerate(label_names):\n",
    "    print(f\"  {idx} - {name}: {train_label_counts[idx]}\")\n",
    "\n",
    "print(\"\\nTest label counts:\")\n",
    "for idx, name in enumerate(label_names):\n",
    "    print(f\"  {idx} - {name}: {test_label_counts[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337929ec",
   "metadata": {},
   "source": [
    "- the classes are perfectly balanced in this dataset\n",
    "\n",
    "Let's split the data into train, validation and test sets using stratification to keep the class ratio (though it could just be random since the classes are well-balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d90c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes:\n",
      "  train: 108000\n",
      "  val:   12000\n",
      "  test:  7600\n"
     ]
    }
   ],
   "source": [
    "split = train_full.train_test_split(\n",
    "    test_size=0.1,\n",
    "    stratify_by_column=\"label\",\n",
    "    seed=99,\n",
    ")\n",
    "\n",
    "train_raw = split[\"train\"]\n",
    "val_raw   = split[\"test\"]\n",
    "test_raw  = test_full  # keep HF test as final test set\n",
    "\n",
    "print(\"Sizes:\")\n",
    "print(\"  train:\", len(train_raw))\n",
    "print(\"  val:  \", len(val_raw))\n",
    "print(\"  test: \", len(test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb935925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label counts: Counter({0: 27000, 1: 27000, 2: 27000, 3: 27000})\n",
      "val label counts:   Counter({3: 3000, 1: 3000, 0: 3000, 2: 3000})\n",
      "test label counts:  Counter({2: 1900, 3: 1900, 1: 1900, 0: 1900})\n"
     ]
    }
   ],
   "source": [
    "print(\"train label counts:\", Counter(train_raw[\"label\"]))\n",
    "print(\"val label counts:  \", Counter(val_raw[\"label\"]))\n",
    "print(\"test label counts: \", Counter(test_raw[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68ac1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "  N samples: 108000\n",
      "  min words: 8\n",
      "  max words: 177\n",
      "  mean words: 37.8\n",
      "  median words: 37.0\n",
      "Val:\n",
      "  N samples: 12000\n",
      "  min words: 8\n",
      "  max words: 151\n",
      "  mean words: 37.9\n",
      "  median words: 37.0\n",
      "Test:\n",
      "  N samples: 7600\n",
      "  min words: 11\n",
      "  max words: 137\n",
      "  mean words: 37.7\n",
      "  median words: 37.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "def text_length_stats(ds, name):\n",
    "    lengths = [len(example[\"text\"].split()) for example in ds]\n",
    "    print(f\"{name}:\")\n",
    "    print(\"  N samples:\", len(lengths))\n",
    "    print(\"  min words:\", min(lengths))\n",
    "    print(\"  max words:\", max(lengths))\n",
    "    print(\"  mean words:\", round(statistics.mean(lengths), 1))\n",
    "    print(\"  median words:\", statistics.median(lengths))\n",
    "\n",
    "text_length_stats(train_raw, \"Train\")\n",
    "text_length_stats(val_raw,   \"Val\")\n",
    "text_length_stats(test_raw,  \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2e0503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths_train = [len(example[\"text\"].split()) for example in train_raw]\n",
    "plt.hist(lengths_train, bins=50)\n",
    "plt.xlabel(\"Text length (words)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of article lengths in AG News (train split)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8607d",
   "metadata": {},
   "source": [
    "# Dataset Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee477711",
   "metadata": {},
   "source": [
    "- most text lengths are around 38 words - and the majority fall under 50 words\n",
    "- since available tokenizers (like GPT-2’s BPE tokenizer) typically need around 1.5 tokens / word (just an estimate)\n",
    "    - 1.5 * 50 = 75 tokens\n",
    "- I will assume the sequence of 128 to be sufficient for each sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b01e142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 50257\n",
      "Pad token id: 50256\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token   # GPT-2 has no pad token by default and we need it for masking the input samples - shorter ones get padded so that all have a fixed length\n",
    "MAX_LEN = 32\n",
    "\n",
    "print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Pad token id:\", tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb64317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9fe70aed1a49a09de496a640350734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes:\n",
      "  input_ids:       torch.Size([16, 128])\n",
      "  attention_mask:  torch.Size([16, 128])\n",
      "  labels:          torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# tokenize splits\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],          # a LIST of raw text strings\n",
    "        truncation=True,        # cut off sequences longer than max_length\n",
    "        padding=\"max_length\",   # pad all sequences in batch to length MAX_LEN\n",
    "        max_length=MAX_LEN,     # the chosen sequence length\n",
    "    )\n",
    "\n",
    "train_tok = train_raw.map(tokenize_batch, batched=True)\n",
    "val_tok   = val_raw.map(tokenize_batch, batched=True)\n",
    "test_tok  = test_raw.map(tokenize_batch, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "for ds_tok in (train_tok, val_tok, test_tok):\n",
    "    ds_tok.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "# dataloaders for from-scratch model\n",
    "train_loader = DataLoader(train_tok, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_tok, batch_size=64, shuffle=False)\n",
    "test_loader  = DataLoader(test_tok, batch_size=64, shuffle=False)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Batch shapes:\")\n",
    "print(\"  input_ids:      \", batch[\"input_ids\"].shape)      # (B, 128)\n",
    "print(\"  attention_mask: \", batch[\"attention_mask\"].shape) # (B, 128)\n",
    "print(\"  labels:         \", batch[\"label\"].shape)          # (B,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d763b20",
   "metadata": {},
   "source": [
    "# Fine-tuning GPT-2 as a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675302e3",
   "metadata": {},
   "source": [
    "- At first \"gpt2\" was used but for cpu and unrestricted training dataset it yealded 40h worth of training for one epoch on cpu\n",
    "- it was therefore changed to \"distilgpt2\" since it has less parameters\n",
    "- the training dataset used was also restricted to a subset of 5k (can be increased if on cpu)\n",
    "- since freezing all transformer weights allowed for quicker training but with a significantly lower classification accuracy, I stuck to training without the weights frozen - slightly longer per epoch but starting at a significantly  higher classification accuracy, requiring less epochs to train to obtain good results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66a5c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    GPT2ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "\n",
    "# model config\n",
    "model_name = \"distilgpt2\"   # smaller, faster than full gpt2\n",
    "# model_name = \"gpt2\"\n",
    "\n",
    "num_labels = len(train_full.features[\"label\"].names)\n",
    "label_names = train_full.features[\"label\"].names\n",
    "print(\"Labels:\", label_names)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# metrics calculations - accuracy + macro F1\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1_macro = f1_metric.compute(\n",
    "        predictions=preds,\n",
    "        references=labels,\n",
    "        average=\"macro\"\n",
    "    )[\"f1\"]\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dfe70a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:      81915648\n",
      "Trainable params:  81915648\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained GPT-2 for sequence classification\n",
    "model_ft = GPT2ForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "\n",
    "# use the same pad token as in the tokenizer\n",
    "model_ft.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model_ft.to(device)\n",
    "\n",
    "# count trainable vs total parameters\n",
    "total_params = sum(p.numel() for p in model_ft.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_ft.parameters() if p.requires_grad)\n",
    "print(f\"Total params:      {total_params}\")\n",
    "print(f\"Trainable params:  {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/gpt2_full\",\n",
    "    eval_strategy=\"epoch\",       # eval at end of each epoch\n",
    "    save_strategy=\"epoch\",             # save checkpoint each epoch\n",
    "    learning_rate=5e-5,                # smaller LR for fine-tuning\n",
    "    per_device_train_batch_size=4,     # small per-device batch\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,     # effective train batch size ≈ 4*4 = 16\n",
    "    num_train_epochs=2,                # we will likely stop earlier via ES\n",
    "    weight_decay=0.01,                 # L2 regularization\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",                  # disable wandb etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d4df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subset size: 5000\n"
     ]
    }
   ],
   "source": [
    "# set a smaller training subset to keep runtime reasonable\n",
    "N_TRAIN = 500\n",
    "train_tok_small = train_tok.select(range(N_TRAIN))\n",
    "print(\"Train subset size:\", len(train_tok_small))\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_ft,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok_small,\n",
    "    eval_dataset=val_tok,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ed12481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julia/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/626 00:09 < 23:22, 0.44 it/s, Epoch 0.02/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# train and measure training time\u001b[39;00m\n\u001b[32m      2\u001b[39m start_train = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m end_train = time.time()\n\u001b[32m      5\u001b[39m ft_train_time = end_train - start_train\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/trainer.py:4110\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4108\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   4109\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m4110\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4111\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   4112\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   4113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1365\u001b[39m, in \u001b[36mGPT2ForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1345\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1346\u001b[39m \u001b[33;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[32m   1347\u001b[39m \u001b[33;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1361\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1362\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1363\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m transformer_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m hidden_states = transformer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1379\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.score(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:925\u001b[39m, in \u001b[36mGPT2Model.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    923\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m outputs = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:413\u001b[39m, in \u001b[36mGPT2Block.forward\u001b[39m\u001b[34m(self, hidden_states, past_key_values, cache_position, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m residual = hidden_states\n\u001b[32m    412\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.ln_1(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m attn_output, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[32m    424\u001b[39m hidden_states = attn_output + residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:313\u001b[39m, in \u001b[36mGPT2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, past_key_values, cache_position, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    311\u001b[39m         value_states = value_states.view(shape_kv).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     query_states, key_states, value_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m.split(\u001b[38;5;28mself\u001b[39m.split_size, dim=\u001b[32m2\u001b[39m)\n\u001b[32m    314\u001b[39m     shape_kv = (*key_states.shape[:-\u001b[32m1\u001b[39m], -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.head_dim)\n\u001b[32m    315\u001b[39m     key_states = key_states.view(shape_kv).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/transformers/pytorch_utils.py:122\u001b[39m, in \u001b[36mConv1D.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    121\u001b[39m     size_out = x.size()[:-\u001b[32m1\u001b[39m] + (\u001b[38;5;28mself\u001b[39m.nf,)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     x = x.view(size_out)\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# train and measure training time\n",
    "start_train = time.time()\n",
    "train_result = trainer.train()\n",
    "end_train = time.time()\n",
    "ft_train_time = end_train - start_train\n",
    "print(f\"Fine-tuning training time (s): {ft_train_time:.1f}\")\n",
    "\n",
    "# evaluate on test set and measure inference time\n",
    "start_eval = time.time()\n",
    "test_metrics = trainer.evaluate(test_tok)\n",
    "end_eval = time.time()\n",
    "ft_inference_time = end_eval - start_eval\n",
    "\n",
    "print(\"Fine-tuned test metrics:\", test_metrics)\n",
    "print(f\"Inference time on test (s): {ft_inference_time:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb2420",
   "metadata": {},
   "source": [
    "# Weight-frozen training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a670444",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = GPT2ForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "\n",
    "model_ft.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# freeze transformer, train only classification head\n",
    "# freeze all transformer layers\n",
    "for param in model_ft.transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# ensure classification head is trainable\n",
    "for param in model_ft.score.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_ft.to(device)\n",
    "\n",
    "# count trainable vs total parameters\n",
    "total_params = sum(p.numel() for p in model_ft.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_ft.parameters() if p.requires_grad)\n",
    "print(f\"Total params:      {total_params}\")\n",
    "print(f\"Trainable params:  {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/gpt2_frozen\",\n",
    "    eval_strategy=\"epoch\",       # eval at end of each epoch\n",
    "    save_strategy=\"epoch\",             # save checkpoint each epoch\n",
    "    learning_rate=5e-5,                # smaller LR for fine-tuning\n",
    "    per_device_train_batch_size=4,     # small per-device batch\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,     # effective train batch size ≈ 4*4 = 16\n",
    "    num_train_epochs=2,                # we will likely stop earlier via ES\n",
    "    weight_decay=0.01,                 # L2 regularization\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",                  # disable wandb etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_ft,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok_small,\n",
    "    eval_dataset=val_tok,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and measure training time\n",
    "start_train = time.time()\n",
    "train_result = trainer.train()\n",
    "end_train = time.time()\n",
    "ft_train_time = end_train - start_train\n",
    "print(f\"Fine-tuning training time (s): {ft_train_time:.1f}\")\n",
    "\n",
    "# evaluate on test set and measure inference time\n",
    "start_eval = time.time()\n",
    "test_metrics = trainer.evaluate(test_tok)\n",
    "end_eval = time.time()\n",
    "ft_inference_time = end_eval - start_eval\n",
    "\n",
    "print(\"Fine-tuned test metrics:\", test_metrics)\n",
    "print(f\"Inference time on test (s): {ft_inference_time:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb83204",
   "metadata": {},
   "source": [
    "# The from-scratch GPT-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch train batch shapes:\n",
      "  input_ids:       torch.Size([16, 128])\n",
      "  attention_mask:  torch.Size([16, 128])\n",
      "  labels:          torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# For fair comparison, use the same subset as for fine-tuning\n",
    "# (if you used N_TRAIN before, reuse it; otherwise set it here)\n",
    "N_TRAIN = 500\n",
    "train_tok_small = train_tok.select(range(N_TRAIN))\n",
    "\n",
    "batch_size_train = 16\n",
    "batch_size_eval = 64\n",
    "\n",
    "train_loader_scratch = DataLoader(train_tok_small, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader_scratch   = DataLoader(val_tok,         batch_size=batch_size_eval,   shuffle=False)\n",
    "test_loader_scratch  = DataLoader(test_tok,        batch_size=batch_size_eval,   shuffle=False)\n",
    "\n",
    "batch = next(iter(train_loader_scratch))\n",
    "print(\"Scratch train batch shapes:\")\n",
    "print(\"  input_ids:      \", batch[\"input_ids\"].shape)\n",
    "print(\"  attention_mask: \", batch[\"attention_mask\"].shape)\n",
    "print(\"  labels:         \", batch[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e23e9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TinyGPTClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        num_labels: int,\n",
    "        max_len: int = 128,\n",
    "        d_model: int = 128,\n",
    "        n_heads: int = 4,\n",
    "        n_layers: int = 2,\n",
    "        dim_ff: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_labels = num_labels\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Token and positional embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb   = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,   # [B, T, D]\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=n_layers,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Classification head: simple linear layer\n",
    "        self.classifier = nn.Linear(d_model, num_labels)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Initialize weights reasonably\n",
    "        nn.init.normal_(self.token_emb.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.pos_emb.weight,   mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.classifier.weight, mean=0.0, std=0.02)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        input_ids:      [B, T]\n",
    "        attention_mask: [B, T] with 1 for real tokens, 0 for padding\n",
    "        \"\"\"\n",
    "        B, T = input_ids.shape\n",
    "        device = input_ids.device\n",
    "\n",
    "        # 1) Embeddings\n",
    "        pos_ids = torch.arange(T, device=device).unsqueeze(0).expand(B, T)  # [B, T]\n",
    "        x = self.token_emb(input_ids) + self.pos_emb(pos_ids)              # [B, T, D]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # 2) Optional causal mask for decoder-style behavior\n",
    "        #    (upper triangular mask to prevent attending to future tokens)\n",
    "        #    For classification, this is not critical, but it makes it \"decoder-like\".\n",
    "        attn_mask = None\n",
    "        # If you want causal mask:\n",
    "        # attn_mask = torch.triu(torch.ones(T, T, device=device) * float(\"-inf\"), diagonal=1)\n",
    "\n",
    "        # 3) Apply transformer encoder (with batch_first=True)\n",
    "        #    src_key_padding_mask expects True for padding tokens\n",
    "        src_key_padding_mask = (attention_mask == 0)  # [B, T], True where padding\n",
    "        h = self.transformer(\n",
    "            x,\n",
    "            mask=attn_mask,\n",
    "            src_key_padding_mask=src_key_padding_mask,\n",
    "        )  # [B, T, D]\n",
    "\n",
    "        # 4) Mean pooling over non-padded tokens\n",
    "        mask = attention_mask.unsqueeze(-1)  # [B, T, 1]\n",
    "        h_masked = h * mask                  # zero out padding\n",
    "        sum_h = h_masked.sum(dim=1)         # [B, D]\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # [B, 1]\n",
    "        pooled = sum_h / lengths            # [B, D]\n",
    "\n",
    "        pooled = self.dropout(pooled)\n",
    "\n",
    "        # 5) Classification head\n",
    "        logits = self.classifier(pooled)    # [B, num_labels]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8df8e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def train_scratch_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs: int = 5,\n",
    "    base_lr: float = 3e-4,\n",
    "    weight_decay: float = 0.01,\n",
    "    max_grad_norm: float = 1.0,\n",
    "    warmup_ratio: float = 0.1,\n",
    "    device=None,\n",
    "):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=base_lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    num_training_steps = num_epochs * len(train_loader)\n",
    "    num_warmup_steps = int(warmup_ratio * num_training_steps)\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "    }\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(input_ids, attention_mask)   # [B, num_labels]\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            global_step += 1\n",
    "\n",
    "            running_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        train_loss_epoch = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "                val_losses.append(loss.item() * input_ids.size(0))\n",
    "\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                all_preds.extend(preds.cpu().tolist())\n",
    "                all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "        val_loss_epoch = sum(val_losses) / len(val_loader.dataset)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(train_loss_epoch)\n",
    "        history[\"val_loss\"].append(val_loss_epoch)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_f1\"].append(val_f1)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d} | \"\n",
    "            f\"train_loss={train_loss_epoch:.4f} | \"\n",
    "            f\"val_loss={val_loss_epoch:.4f} | \"\n",
    "            f\"val_acc={val_acc:.4f} | \"\n",
    "            f\"val_f1={val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c836a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julia/Documents/lingwistyka/computational-linguistics/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.9757 | val_loss=0.4655 | val_acc=0.8349 | val_f1=0.8341\n",
      "Epoch 02 | train_loss=0.2170 | val_loss=0.4683 | val_acc=0.8604 | val_f1=0.8605\n",
      "Epoch 03 | train_loss=0.0383 | val_loss=0.6199 | val_acc=0.8641 | val_f1=0.8644\n",
      "Epoch 04 | train_loss=0.0081 | val_loss=0.6553 | val_acc=0.8718 | val_f1=0.8711\n",
      "Epoch 05 | train_loss=0.0017 | val_loss=0.6607 | val_acc=0.8738 | val_f1=0.8733\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "num_labels = len(train_full.features[\"label\"].names)\n",
    "\n",
    "tiny_model = TinyGPTClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    num_labels=num_labels,\n",
    "    max_len=MAX_LEN,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    dim_ff=512,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "history_scratch = train_scratch_model(\n",
    "    tiny_model,\n",
    "    train_loader_scratch,\n",
    "    val_loader_scratch,\n",
    "    num_epochs=5,\n",
    "    base_lr=3e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f652114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch test metrics: {'accuracy': 0.8607894736842105, 'f1_macro': 0.8602538755104127, 'inference_time_s': 3.532940626144409}\n",
      "Scratch model parameter count: 6846340\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def eval_on_test(model, test_loader, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro, \"inference_time_s\": total_time}\n",
    "\n",
    "scratch_test_metrics = eval_on_test(tiny_model, test_loader_scratch)\n",
    "print(\"Scratch test metrics:\", scratch_test_metrics)\n",
    "\n",
    "scratch_param_count = sum(p.numel() for p in tiny_model.parameters())\n",
    "print(\"Scratch model parameter count:\", scratch_param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f422bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computational-linguistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
